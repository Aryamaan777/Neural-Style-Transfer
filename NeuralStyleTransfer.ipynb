{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralStyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0SQ6DZinG/cmpZJbKZetj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aryamaan777/Neural-Style-Transfer/blob/main/NeuralStyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o0XwC85Jnsg"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from PIL import Image\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.models as models\r\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weqYzurSKTi_"
      },
      "source": [
        "class VGG(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(VGG,self).__init__()\r\n",
        "    self.chosen_features=[\"0\",\"5\",\"10\",\"19\",\"28\"]\r\n",
        "    self.model=models.vgg19(pretrained=True).features[:29]\r\n",
        "\r\n",
        "  def forward(self,x):\r\n",
        "    features=[]\r\n",
        "    for layer_num,layer in enumerate(self.model):\r\n",
        "      x=layer(x)\r\n",
        "      if (str(layer_num) in self.chosen_features):\r\n",
        "        features.append(x)\r\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdFOEBXfLLzF"
      },
      "source": [
        "def load_image(image_name):\r\n",
        "  image=Image.open(image_name)\r\n",
        "  image=loader(image).unsqueeze(0)\r\n",
        "  return image.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSU2qVXeLXRK"
      },
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "imsize=356"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F04OqsEcLsZZ"
      },
      "source": [
        "loader=transforms.Compose(\r\n",
        "    [\r\n",
        "     transforms.Resize((imsize,imsize)),\r\n",
        "     transforms.ToTensor()\r\n",
        "    ]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjyCQKlRL5QB"
      },
      "source": [
        "original_img=load_image(\"messi.jpg\")\r\n",
        "style_img=load_image(\"lightning.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soYacv7jM-Ql"
      },
      "source": [
        "generated=original_img.clone().requires_grad_(True)\r\n",
        "model=VGG().to(device).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpqmow1pNJdn"
      },
      "source": [
        "total_steps=6000\r\n",
        "learning_rate=0.001\r\n",
        "alpha=1\r\n",
        "beta=0.01\r\n",
        "optimizer=optim.Adam([generated],lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WONlqMydNWhl",
        "outputId": "8c7f75a6-8b18-4cd1-ac38-6420c32ad493"
      },
      "source": [
        "for step in range(total_steps):\r\n",
        "  generated_features=model(generated)\r\n",
        "  original_img_features=model(original_img)\r\n",
        "  style_features=model(style_img)\r\n",
        "\r\n",
        "  style_loss=original_loss=0\r\n",
        "  \r\n",
        "  for gen_feature, orig_feature, style_feature in zip(generated_features,original_img_features,style_features):\r\n",
        "    batch_size,channel,height,width=gen_feature.shape\r\n",
        "    original_loss += torch.mean((gen_feature-orig_feature)**2)\r\n",
        "    G=gen_feature.view(channel,height*width).mm(\r\n",
        "        gen_feature.view(channel,height*width).t()\r\n",
        "    )\r\n",
        "\r\n",
        "    A=style_feature.view(channel,height*width).mm(\r\n",
        "        style_feature.view(channel,height*width).t()\r\n",
        "    )\r\n",
        "\r\n",
        "    style_loss += torch.mean((G-A)**2)\r\n",
        "  \r\n",
        "  total_loss=alpha*original_loss+beta*style_loss\r\n",
        "  optimizer.zero_grad()\r\n",
        "  total_loss.backward()\r\n",
        "  optimizer.step()\r\n",
        "\r\n",
        "  if(step%200==0):\r\n",
        "    print(total_loss,step)\r\n",
        "    save_image(generated,\"generated.jpg\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(706261.7500, device='cuda:0', grad_fn=<AddBackward0>) 0\n",
            "tensor(224398.7344, device='cuda:0', grad_fn=<AddBackward0>) 200\n",
            "tensor(20543.6914, device='cuda:0', grad_fn=<AddBackward0>) 400\n",
            "tensor(8236.5371, device='cuda:0', grad_fn=<AddBackward0>) 600\n",
            "tensor(6677.7939, device='cuda:0', grad_fn=<AddBackward0>) 800\n",
            "tensor(5710.4585, device='cuda:0', grad_fn=<AddBackward0>) 1000\n",
            "tensor(4992.0571, device='cuda:0', grad_fn=<AddBackward0>) 1200\n",
            "tensor(4414.6987, device='cuda:0', grad_fn=<AddBackward0>) 1400\n",
            "tensor(3932.2847, device='cuda:0', grad_fn=<AddBackward0>) 1600\n",
            "tensor(3517.6711, device='cuda:0', grad_fn=<AddBackward0>) 1800\n",
            "tensor(3155.9307, device='cuda:0', grad_fn=<AddBackward0>) 2000\n",
            "tensor(2832.4741, device='cuda:0', grad_fn=<AddBackward0>) 2200\n",
            "tensor(2540.7439, device='cuda:0', grad_fn=<AddBackward0>) 2400\n",
            "tensor(2275.9248, device='cuda:0', grad_fn=<AddBackward0>) 2600\n",
            "tensor(2035.5204, device='cuda:0', grad_fn=<AddBackward0>) 2800\n",
            "tensor(1817.6431, device='cuda:0', grad_fn=<AddBackward0>) 3000\n",
            "tensor(1619.2413, device='cuda:0', grad_fn=<AddBackward0>) 3200\n",
            "tensor(1439.1019, device='cuda:0', grad_fn=<AddBackward0>) 3400\n",
            "tensor(1275.4863, device='cuda:0', grad_fn=<AddBackward0>) 3600\n",
            "tensor(1128.4686, device='cuda:0', grad_fn=<AddBackward0>) 3800\n",
            "tensor(997.9037, device='cuda:0', grad_fn=<AddBackward0>) 4000\n",
            "tensor(884.0363, device='cuda:0', grad_fn=<AddBackward0>) 4200\n",
            "tensor(785.7197, device='cuda:0', grad_fn=<AddBackward0>) 4400\n",
            "tensor(702.0558, device='cuda:0', grad_fn=<AddBackward0>) 4600\n",
            "tensor(629.2546, device='cuda:0', grad_fn=<AddBackward0>) 4800\n",
            "tensor(568.1803, device='cuda:0', grad_fn=<AddBackward0>) 5000\n",
            "tensor(514.7461, device='cuda:0', grad_fn=<AddBackward0>) 5200\n",
            "tensor(468.9276, device='cuda:0', grad_fn=<AddBackward0>) 5400\n",
            "tensor(431.4115, device='cuda:0', grad_fn=<AddBackward0>) 5600\n",
            "tensor(398.1881, device='cuda:0', grad_fn=<AddBackward0>) 5800\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}